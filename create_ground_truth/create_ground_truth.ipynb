{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e1777a-5dc2-4d3d-9760-22fa0bd7e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b23dc5-a9db-4113-a0e0-e348a79b5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client =  Groq(api_key = os.environ['GROQ_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d14b2f-1c78-4917-b3d6-5e24e44bcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ed1d19-ac84-4416-a42d-f9669f15ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate my assistant who works with me in a Q and A project .\n",
    "Formulate 3 questions people might ask based on the record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. Make sure the questions should be in Vietnamese and the output can be parsed into json format.\n",
    "\n",
    "The record:\n",
    "\n",
    "question: {question}\n",
    "answer: {answer}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", \"question3\"] (no need to rewrite question1, question2, question3, just replace them with your question and make sure to answer immediately without any unrelated things like: \"Here are the questions and answers in JSON format:\")\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea0977d5-4db2-481f-b96f-5e6bb25f7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    # print(prompt)\n",
    "    retries = 5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model='llama3-groq-70b-8192-tool-use-preview',\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            json_response = response.choices[0].message.content\n",
    "            return json_response\n",
    "        except HTTPError as e:\n",
    "            if e.response.status_code == 429:  # Rate limit error\n",
    "                retry_after = float(e.response.json()['error']['message'].split('in ')[-1].split('s')[0])\n",
    "                time.sleep(retry_after)\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            if i < retries - 1:\n",
    "                time.sleep(2 ** i)  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "def process_document(doc):\n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        return None\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    return (doc_id, questions)\n",
    "# Initialize ThreadPoolExecutor\n",
    "pool = ThreadPoolExecutor(max_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe081828-0189-4f3a-8dd8-f61c8936a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████    | 34/40 [00:12<00:08,  1.42s/it]"
     ]
    }
   ],
   "source": [
    "chunk_size = 40\n",
    "start_chunk = 0 # Starting chunk index\n",
    "end_chunk = (len(documents) // chunk_size)  # Ending chunk index\n",
    "print(end_chunk)\n",
    "for i in range(start_chunk, end_chunk):\n",
    "    results = {}\n",
    "    chunk_start = i * chunk_size\n",
    "    chunk_end = chunk_start + chunk_size\n",
    "    # print(i + 42, chunk_start, chunk_end)\n",
    "    chunk = documents[chunk_start:chunk_end]\n",
    "\n",
    "    # Use map_progress to process documents\n",
    "    processed_results = map_progress(pool, chunk, process_document)\n",
    "\n",
    "    # Store the results incrementally\n",
    "    for result in processed_results:\n",
    "        if result is not None:\n",
    "            doc_id, questions = result\n",
    "            results[doc_id] = questions\n",
    "\n",
    "    # Save the results to a file\n",
    "    file_name = f'../data/vietnamese_rag/ground_truth_data/ground_truth{i + 1}.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Chunk {i} processed and saved to {file_name}\")\n",
    "\n",
    "    # Wait for 1 minute to reset rate limit\n",
    "    time.sleep(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "160a9301-179d-4928-997a-08866cf15ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 2/2 [00:00<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'37b2c2d3': 'Minh Tú đã đạt được thành tích gì trong chương trình Asia’ Next Top Model mùa thứ 5?\\nMinh Tú đã vượt qua sự sợ hãi để hoàn thành tốt phần thử thách đi catwalk khi bị treo lơ lửng trên một tòa nhà cao tầng và đạt vị trí thứ 2 trong đêm chung kết của chương trình.', '809411de': '[\"Tại sao sương mù xuất hiện dày đặc ở TP HCM vào sáng 21/9?\", \"Mức ô nhiễm của TP HCM có ảnh hưởng gì đến sương mù?\", \"Sương mù xuất hiện dày đặc ở TP HCM có thể được giảm thiểu bằng cách nào?\"]'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|████████████████████▏     | 31/40 [00:05<00:04,  2.22it/s]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# Use map_progress to process documents\n",
    "processed_results = map_progress(pool, documents[0:2], process_document)\n",
    "\n",
    "# Store the results\n",
    "for result in processed_results:\n",
    "    if result is not None:\n",
    "        doc_id, questions = result\n",
    "        results[doc_id] = questions\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715eaf2-d9e7-4930-8cee-31246e52105d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
