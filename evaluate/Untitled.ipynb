{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edb6230-202f-46cf-a4de-1ab981aeb20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9c43da-58d5-4510-9075-dcbbf31caefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84fdeaf9-b96d-43cd-8d49-438286ba8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235959f9-c839-4514-8ade-f04f5f7dff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Minh Tú đã gặp khó khăn gì trong thử thách đi catwalk tại Asia's Next Top Model mùa 5?\",\n",
       " 'Group': 'General',\n",
       " 'document': '75fafd29'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv('../data/vietnamese_rag/ground_truth_data/ground_truth_data.csv')\n",
    "\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f36b63-f1e8-4b28-950e-81dd44fbe53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vietnamese-questions'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"group\": {\"type\": \"keyword\"},\n",
    "            \"context\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_context_answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"vietnamese-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f599084f-08b7-4346-baf2-b69c272f6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████| 6089/6089 [02:19<00:00, 43.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_vectors(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def process_documents(documents, index_name, es_client):\n",
    "    document_question_vector_list = load_vectors(f'../data/vietnamese_rag/question_vector_pickle/question_vector.pkl')\n",
    "    document_answer_vector_list = load_vectors(f'../data/vietnamese_rag/answer_vector_pickle/answer_vector.pkl')\n",
    "    document_context_vector_list = load_vectors(f'../data/vietnamese_rag/context_vector_pickle/context_vector.pkl')\n",
    "    document_qta_vector_list = load_vectors(f'../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector.pkl')\n",
    "    for j in range(len(documents)):\n",
    "        documents[j]['question_vector'] = document_question_vector_list[j]['question_vector']\n",
    "        documents[j]['answer_vector'] = document_answer_vector_list[j]['answer_vector']\n",
    "        documents[j]['context_vector'] = document_context_vector_list[j]['context_vector']\n",
    "        documents[j]['question_context_answer_vector'] = document_qta_vector_list[j]['question_context_answer_vector']\n",
    "    for doc in tqdm(documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "process_documents(documents, index_name, es_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa170c6-673d-4ed5-bbea-0230a5a501bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760084ab-4984-4d9f-8556-901373da452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Our own implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)\n",
    "\n",
    "def elastic_search_hybrid_rrf(field, query, vector, group, k=60):\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"group\": group\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"context\", \"question\", \"answer\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"group\": group\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    rrf_scores = {}\n",
    "    # Calculate RRF using vector search results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Adding keyword search result scores\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff09c0e-a4b3-4514-8349-00933d1335dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_vector_hybryd(q):\n",
    "    question = q['question']\n",
    "    group = q['Group']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('context_vector', question, v_q, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1134ca1d-7718-4233-8e0e-3cba40656a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_context_answer_vector_hybryd(q):\n",
    "    question = q['question']\n",
    "    group = q['Group']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('question_context_answer_vector', question, v_q, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206f1c30-8a38-4bcd-803c-e38ae8c265b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_vector_hybryd(q):\n",
    "    question = q['question']\n",
    "    group = q['Group']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('answer_vector', question, v_q, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e48d07f-66a4-49a6-86cc-d67d21fbe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_hybryd(q):\n",
    "    # print(q)\n",
    "    question = q['question']\n",
    "    group = q['Group']\n",
    "    if not isinstance(question, str):\n",
    "        print(question)\n",
    "        raise TypeError(f\"Expected question to be a string, but got {type(question)}\")\n",
    "    v_q = model.encode(question)\n",
    "    return elastic_search_hybrid_rrf('question_vector', question, v_q, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9a6d854-1131-4d4e-bfec-781f3dd1775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 29203/29203 [26:54<00:00, 18.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9536349005239187, 'mrr': 0.8312433654076612}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_vector_hybryd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd728e3-f54f-497c-9429-e7f22366d52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
